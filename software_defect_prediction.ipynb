{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\NITR_CS_PL4K\\Downloads\\JM1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79320b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ef579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df. size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbfc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f842d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf24b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea71229",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac5086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d09afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = df.shape\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fe716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad22832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LOC_BLA0K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac364c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode labels into numeric format\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y = label_encoder.fit_transform(y)\n",
    "# y_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into features (X) and target (y)\n",
    "X = df.drop(columns=['Defective'])  # Replace 'target_column' with the name of your target column\n",
    "y = df['Defective']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape (features):\", X_train.shape)\n",
    "print(\"Testing set shape (features):\", X_test.shape)\n",
    "print(\"Training set shape (target):\", y_train.shape)\n",
    "print(\"Testing set shape (target):\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f429e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array\n",
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d70003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers with different kernels\n",
    "classifiers = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVM Sigmoid\": SVC(kernel='sigmoid', random_state=42),\n",
    "    \"svm_linear\" : SVC(kernel='linear', random_state=42),\n",
    "    \"svm_poly_degree_3\" : SVC(kernel='poly', degree=3, random_state=42),\n",
    "    \"svm_poly_degree_4\" : SVC(kernel='poly', degree=4, random_state=42),\n",
    "    \"svm_rbf\": SVC(kernel='rbf', random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dictionaries to store evaluation metrics\n",
    "metrics_dict = {\n",
    "    \"Classifier\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac44f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each classifier\n",
    "for clf_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_np, y_train)  # Use NumPy arrays instead of DataFrames\n",
    "    predictions = classifier.predict(X_test_np)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    # Create confusion matrix table\n",
    "    conf_matrix_table = PrettyTable()\n",
    "    conf_matrix_table.title = f\"Confusion Matrix for {clf_name}\"\n",
    "    conf_matrix_table.field_names = [\"\", \"Predicted 0\", \"Predicted 1\"]\n",
    "    \n",
    "    # Add rows for each actual class\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        conf_matrix_table.add_row([f\"Actual {i}\", conf_matrix[i][0], conf_matrix[i][1]])\n",
    "    \n",
    "    # Print confusion matrix for each classifier\n",
    "    print(conf_matrix_table)\n",
    "\n",
    "            \n",
    "    # Calculate metrics\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    precision = np.where(np.sum(conf_matrix, axis=0) == 0, 0, np.diag(conf_matrix) / np.sum(conf_matrix, axis=0))\n",
    "    recall = np.where(np.sum(conf_matrix, axis=1) == 0, 0, np.diag(conf_matrix) / np.sum(conf_matrix, axis=1))\n",
    "    f1_score = np.where((precision + recall) == 0, 0, 2 * precision * recall / (precision + recall))\n",
    "\n",
    "    # Store evaluation metrics in the dictionary\n",
    "    metrics_dict[\"Classifier\"].append(clf_name)\n",
    "    metrics_dict[\"Accuracy\"].append(accuracy)\n",
    "    metrics_dict[\"Precision\"].append(np.mean(precision))\n",
    "    metrics_dict[\"Recall\"].append(np.mean(recall))\n",
    "    metrics_dict[\"F1 Score\"].append(np.mean(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PrettyTable for evaluation metrics\n",
    "metrics_table = PrettyTable()\n",
    "metrics_table.field_names = [\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "for i in range(len(metrics_dict[\"Classifier\"])):\n",
    "    metrics_table.add_row([\n",
    "        metrics_dict[\"Classifier\"][i],\n",
    "        metrics_dict[\"Accuracy\"][i],\n",
    "        metrics_dict[\"Precision\"][i],\n",
    "        metrics_dict[\"Recall\"][i],\n",
    "        metrics_dict[\"F1 Score\"][i]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation metrics table\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed55686",
   "metadata": {},
   "source": [
    "# Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confuion mtrix  and bar graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77357a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrices\n",
    "confusion_matrices = {\n",
    "    \"Decision Tree\": np.array([[1318, 251], [233, 117]]),\n",
    "    \"Random Forest\": np.array([[1523, 46], [284, 66]]),\n",
    "    \"k-Nearest Neighbors\": np.array([[1483, 86], [295, 55]]),\n",
    "    \"SVM Sigmoid\": np.array([[1535, 34], [320, 30]])\n",
    "}\n",
    "\n",
    "# Plot confusion matrices as heatmaps\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (model, matrix) in enumerate(confusion_matrices.items(), start=1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.heatmap(matrix, annot=True, cmap='Blues', fmt='g', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix for {model}')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define classifiers and corresponding evaluation metrics\n",
    "classifiers = ['Decision Tree', 'Random Forest', 'k-Nearest Neighbors', 'SVM Sigmoid']\n",
    "accuracy = [0.7478, 0.8280, 0.8015, 0.8155]\n",
    "precision = [0.5839, 0.7161, 0.6121, 0.6481]\n",
    "recall = [0.5872, 0.5796, 0.5512, 0.5320]\n",
    "f1_score = [0.5854, 0.5940, 0.5551, 0.5208]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar plots for each metric\n",
    "bars1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
    "bars2 = ax.bar(x - 0.5*width, precision, width, label='Precision')\n",
    "bars3 = ax.bar(x + 0.5*width, recall, width, label='Recall')\n",
    "bars4 = ax.bar(x + 1.5*width, f1_score, width, label='F1 Score')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Classifier')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Classifier Performance Metrics')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classifiers)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels on top of the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate('{}'.format(round(height, 2)),\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Call the function to add labels\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "add_labels(bars3)\n",
    "add_labels(bars4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a849f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = np.array([[1318, 251], [233, 117]])\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix for Decision Tree')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9463939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = np.array([[1523, 46], [284, 66]])\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = np.array([[1483, 86], [295, 55]])\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix for k-Nearest Neighbors')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = np.array([[1535, 34], [320, 30]])\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'], \n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix for SVM Sigmoid')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "data = {\n",
    "    'Classifier': ['Decision Tree', 'Random Forest', 'k-Nearest Neighbors', 'SVM Sigmoid'],\n",
    "    'TN': [1318, 1523, 1483, 1535],\n",
    "    'TP': [117, 66, 55, 30],\n",
    "    'FP': [251, 46, 86, 34],\n",
    "    'FN': [233, 284, 295, 320]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the 'Classifier' column as the index\n",
    "df.set_index('Classifier', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947163e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "data = {\n",
    "    'Classifier': ['Decision Tree', 'Random Forest', 'k-Nearest Neighbors', 'SVM Sigmoid'],\n",
    "    'Accuracy': [0.7478, 0.8280, 0.8015, 0.8155],\n",
    "    'Precision': [0.5839, 0.7161, 0.6121, 0.6481],\n",
    "    'Recall': [0.5872, 0.5796, 0.5512, 0.5320],\n",
    "    'F1 Score': [0.5854, 0.5940, 0.5551, 0.5208]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the 'Classifier' column as the index\n",
    "df.set_index('Classifier', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46e459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
